<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>HN - datascience</title><link href="http://localhost:8000/" rel="alternate"></link><link href="http://localhost:8000/feeds/datascience.atom.xml" rel="self"></link><id>http://localhost:8000/</id><updated>2018-12-09T00:00:00+05:30</updated><entry><title>Apache Toree notebook for Spark</title><link href="http://localhost:8000//apache-toree-notebook-for-spark.html" rel="alternate"></link><published>2018-12-09T00:00:00+05:30</published><updated>2018-12-09T00:00:00+05:30</updated><author><name>HN</name></author><id>tag:localhost,2018-12-09://apache-toree-notebook-for-spark.html</id><summary type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;Apache Toree is a jupyter kernel. It runs the spark application in client mode,
so that we can interact with the application via console. By enabling this in
standard jupyter notebook we can easily connect with any spark cluster or standalone servers,
via this we get all the flexibility of â€¦&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;Apache Toree is a jupyter kernel. It runs the spark application in client mode,
so that we can interact with the application via console. By enabling this in
standard jupyter notebook we can easily connect with any spark cluster or standalone servers,
via this we get all the flexibility of the jupyter notebook. Toree notebook supports
pyspark and R also with special magic constructs.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here I&amp;#8217;m explaining how we can install and configure toree for spark based testing
environment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_how_to_configure_toree_with_default_jupyter_notebook"&gt;How to configure toree with default jupyter notebook&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;# Current latest version, pick the
pip install toree==0.3.0
jupyter toree install --user --spark_home=/mnt/haridas/packages/spark-2.1.2-bin-hadoop2.7&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To confirm the new kernel got installed to jupyter correctly,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;jupyter kernelspec list

Available kernels:
  apache_toree_scala    /home/haridas/.local/share/jupyter/kernels/apache_toree_scala
  python3               /home/haridas/ENV3/share/jupyter/kernels/python3&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If above commands ran successful then we are good to go with running new kernel
with jupyter web UI or on the console mode.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_access_the_toree_via_jupyter"&gt;Access the Toree via jupyter&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_notebook_mode"&gt;Notebook mode&lt;/h3&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;jupyter notebook --no-browser --ip 0.0.0.0 --port 8080&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Go to browser on this jupyter application, when creating the new notebook, you
can now have option to create toree notebook also along with python standard notebook
type.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_console_mode"&gt;Console mode&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Sometime you might need to directly work on small scripts ore test few things against
spark cluster or checking the scala magics ;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Make use of the console version jupyter with the new kernel. Now you get the standard
ipython like console via that we can interact with the spark cluster or write scala
codes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code&gt;jupyter console --kernel=apache_toree_scala&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_customie_toree_configuration"&gt;Customie toree configuration&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Default settings of the spark application is very minimal, which may be not enough
to test with big files or make use of the available resources in your machine. To
do that you need to update the default configurations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;By default spark and driver program make uses only 1GB of heap size, and number
of executors will be 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To change the configuration it&amp;#8217;s pretty easy, you can check the available options
from  &lt;code&gt;spark-submit --help&lt;/code&gt; command, and pass them on bellow environment variable
before running the toree notebook.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When picking options from &lt;code&gt;spark-submit&lt;/code&gt; ensure your cluster is of type standalone,
or standalone-cluster-mode or yarn cluster mode. The options are bit different between
the cluster managers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;export SPARK_OPTS="--jars /home/haridas/custom1.jar:/home/haridas/custom2.jar \
    --driver-memory=5g \
    --executor-memory=5g \
    --num-executors 3"
jupyter console --kernel=apache_toree_scala&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_connect_toree_with_remote_spark_cluster"&gt;Connect Toree with remote spark cluster&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here only we only need to make use of the spark-submit arguments.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;export SPARK_OPTS="--master spark://&amp;lt;host&amp;gt;:7077 ..."&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Thats all for now, have fun with spark cluster and get the same flexibility of ipython notebook !&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_reference"&gt;Reference&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="olist arabic"&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blog.cloudera.com/blog/2014/05/apache-spark-resource-management-and-yarn-app-models/" class="bare"&gt;https://blog.cloudera.com/blog/2014/05/apache-spark-resource-management-and-yarn-app-models/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;spark-submit --help&lt;/code&gt; command.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://toree.apache.org/" class="bare"&gt;https://toree.apache.org/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/apache/incubator-toree/blob/master/etc/examples/notebooks/magic-tutorial.ipynb" class="bare"&gt;https://github.com/apache/incubator-toree/blob/master/etc/examples/notebooks/magic-tutorial.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="spark"></category><category term="toree"></category></entry></feed>