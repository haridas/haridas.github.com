<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>HN - devops</title><link href="https://haridas.in/" rel="alternate"></link><link href="https://haridas.in/feeds/devops.atom.xml" rel="self"></link><id>https://haridas.in/</id><updated>2018-09-19T00:00:00+05:30</updated><entry><title>Production ready docker images</title><link href="https://haridas.in/production-ready-docker-images.html" rel="alternate"></link><published>2018-09-19T00:00:00+05:30</published><updated>2018-09-19T00:00:00+05:30</updated><author><name>HN</name></author><id>tag:haridas.in,2018-09-19:/production-ready-docker-images.html</id><summary type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;Docker is a de facto standard across all the software development pipeline.
Very few and legacy systems aren&amp;#8217;t using dockers. Docker is very easy to starts with
for the development phase, but taking the docker into production level involves
bunch security concerts. Here I&amp;#8217;m explaining few important points …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;Docker is a de facto standard across all the software development pipeline.
Very few and legacy systems aren&amp;#8217;t using dockers. Docker is very easy to starts with
for the development phase, but taking the docker into production level involves
bunch security concerts. Here I&amp;#8217;m explaining few important points that need to be
taken care when packaging the docker for production environments.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Most of the docker based project comes with their own &lt;code&gt;Dockerfile&lt;/code&gt;, so that the
project can be packaged and shipped in Docker image format. There are multiple
benefits doing this way,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="olist arabic"&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;
&lt;p&gt;Easy to package any application into fully isolated docker image.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Best tooling around the docker makes it simpler to manage docker images and
containers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Docker container provides clean OS Process level isolation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Control the resource usage of docker container via restricting CPU and Memory
conception.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Build once deploy many principle, this ensures clean release management.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Above listed are well known facts with the docker containers. But when we move into
production environments there are not that well discussed facts about the docker
which surely compromise the security of the production environments.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The main points that need to be taken care when packaging and deploying docker
are,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="olist arabic"&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;
&lt;p&gt;Ensure Docker images are build in trusted environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Docker container processes shouldn&amp;#8217;t run in root privilege.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enable all the host level securities and firewall setup. eg; SELinux&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Principle of least privilege&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_secure_docker_images"&gt;Secure Docker images&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When creating docker images follow these steps to ensure the security of the
docker images.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="_make_use_of_user_keyword_in_dockerfile"&gt;Make use of USER keyword in Dockerfile&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This will ensure the docker container process won&amp;#8217;t run in root user mode or
with UID 0. If we aren&amp;#8217;t setup the non-root user with in the image then the
docker container run with UID 0 by default. This means even the normal user
who runs the docker gets the root level privileges on the host machine, and
the docker container can modify contents in host /etc folder if wants.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To illustrate this, Just pull a &lt;code&gt;ubuntu&lt;/code&gt; image from dockerhub and test,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ docker run -it --rm -v /etc:/host-etc ubuntu:latest bash
(inside-docker-root)# rm /host-etc/hosts&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Here we can remove the file from host etc folder.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We can run the container with given &lt;code&gt;uid:gid&lt;/code&gt; pair at container startup time. This
is a simple way to restrict the privilege of processes running inside the docker.
But main downside for this method is that the user has to make sure
docker isn&amp;#8217;t started with root privilege, the image itself isn&amp;#8217;t internally equipped
with the non-root user privilege. Because of this reason this method isn&amp;#8217;t recommended
for the production environments. For testing purpose this is a good option.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;$ docker run -it --rm --user 1000:1000 -v /etc:/hostEtc ubuntu:latest bash
(uid-1000) $ rm /hostEtc/hosts&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Lets see how we can embedded this restriction when we creating the docker image
itself. See a sample Dockerfile definition for the same.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;# Dockerfile example
FROM ubuntu:18.04

ENV APP_USER=docker_app

# Create user
RUN useradd --user-group --create-home --shell /bin/bash \
    --comment "Docker image user" $APP_USER

# Add user to sudoers ( OPTIONAL, Disable it in production environments )
RUN yum install -y sudo gettext wget telnet net-tools python-setuptools &amp;amp;&amp;amp; \
    echo "$APP_USER ALL=(ALL) NOPASSWD: ALL" &amp;gt;&amp;gt; /etc/sudoers

USER $APP_USER
WORKDIR /home/$APP_USER&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you build the docker image from this custom Dockerfile, which enforce the container
process to run with privilege of user named &lt;code&gt;docker_app&lt;/code&gt;. This is enforced by the
keyword &lt;code&gt;USER&lt;/code&gt; in Dockerfile, it to switches the default docker user (root)
to the custom username or uid.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;docker build . -t ubuntu-custom
docker run -it --rm ubuntu-custom /bin/bash
(docker_app)$&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_enable_user_namespace"&gt;Enable user namespace&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is the most secured method to secure the docker container from privileged
access issues. This guarantees that irrespective what the Dockerfile author does,
user namespace ensure the docker container processes never run with uid 0.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Username space does this by the help of UID mapping at host machine level, and this
is enabled with the &lt;code&gt;dockerd&lt;/code&gt; docker daemon side. That means only the admin with full
host machine access can configure the docker daemon to run with user namespace enabled
mode.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock important"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Important&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
To enable this feature you need docker version 1.13 or above,
and Linux kernel supports this featuer from version 3.11 and above.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Configuration at the system level is trivial one,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="olist arabic"&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;
&lt;p&gt;Change the &lt;code&gt;/etc/docker/daemon.json&lt;/code&gt; as below,&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-json" data-lang="json"&gt;{
    "userns-remap": "host-user1"
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Ensuer &lt;code&gt;host-user1&lt;/code&gt; exists in Host machine.
. Create subuid and subgid mapping file, as bellow&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;#UID mapping
$ cat /etc/subuid
host-user1:231072:65536

#GID mapping
$ cat /etc/subgid
host-user1:231072:65536&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The above UID and GID mapping files configure the offset of USER ids used inside
the docker container. ie; If UID inside the docker is 0 ( root ), then it gets
mapped UID 231072 (231072 + 0 = 231072) in host machine. This offset helps to
ensure the UID never be root uid 0. This is the same case for GID also.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock note"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Note&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
When doing this mapping we generally pick a higher number for the UID and GUID which are
not generally used on the host machine. Both UID and GID are 32-bit number, so
we can pick higher range for the docker users.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_supply_secrets_and_configurations_via_tmpfs"&gt;Supply secrets and configurations via tmpfs&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Generally the secrets are stored in a volume or folder and attached to the docker
via volume mounting. In case of configuration it&amp;#8217;s fine to pass them via
environment variables. Application should careful with the secrets,
as it shouldn&amp;#8217;t accidentally write the secrets into log files and send out in
plain text format to other components.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you are using the Docker container managers like &lt;code&gt;kubernetes&lt;/code&gt;, &lt;code&gt;swarm&lt;/code&gt; etc then
they comes with the secret management facilities by default. Please make use of it
if you are using any of these tools. For the plain Docker running scenario the
admin has to take care the volume mounting securely making use of &lt;code&gt;tmpfs&lt;/code&gt; and
a custom volume driver which bridges the connection between secret storage and docker
container. One example for this is Hashicorp Vault.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonitionblock important"&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class="icon"&gt;
&lt;div class="title"&gt;Important&lt;/div&gt;
&lt;/td&gt;
&lt;td class="content"&gt;
Making use of Hashicorp Vault with custom volume driver is neat method
to share the secrets and configuration securely.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_unless_required_dont_use_cmd_in_dockerfile"&gt;Unless required don&amp;#8217;t use CMD in Dockerfile&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This isn&amp;#8217;t that critical, but still a best practice to avoid unnecessary arguments
passing via command line when running the docker container.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Making a container immutable is ideal option, ie; it doesn&amp;#8217;t take any extra
command line arguments at run time. If it required any configuration values read
from the Environment variables and use volumes for secret management.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To enforce this, use only &lt;code&gt;ENTRYPOINT&lt;/code&gt; in Dockerfile.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="highlight"&gt;&lt;code class="language-text" data-lang="text"&gt;ENTRYPOINT ['python', '/web.py', '--port=5000', '--host=0.0.0.0']&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="_enable_linux_security_modules_like_selinux"&gt;Enable Linux Security Modules like SELinux.&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This should be done in all cases to ensure only authorized operations happens in
Kernel and user space level. SELinux ensure interaction between all type of
resources ( file, socket, pid, port kernel objects, etc..) and process is in check.
SELinux uses Mandatory access control ( MAC ), this means all the interaction
between the resource and process need to be defined in the selinux policy, No other
interaction happens across the system.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Selinux or similar system level security tools based on Linux Security Module
provides general security for the host machine.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="devops"></category><category term="docker"></category><category term="security"></category></entry><entry><title>How to put Encrypted Contents on Cloud Storages</title><link href="https://haridas.in/how-to-put-encrypted-contents-on-cloud-storages.html" rel="alternate"></link><published>2012-07-27T00:00:00+05:30</published><updated>2012-07-27T00:00:00+05:30</updated><author><name>HN</name></author><id>tag:haridas.in,2012-07-27:/how-to-put-encrypted-contents-on-cloud-storages.html</id><summary type="html">&lt;p&gt;There is a plenty of cloud storage services out there for free.
It's very convenient and flexible that we can sync our local files with
remote storage. For simple and non-sensitive contents this  is very useful.
But we know that the contents on the net are being open. There is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;There is a plenty of cloud storage services out there for free.
It's very convenient and flexible that we can sync our local files with
remote storage. For simple and non-sensitive contents this  is very useful.
But we know that the contents on the net are being open. There is a chance for
those contents will get read by others.&lt;/p&gt;
&lt;p&gt;I use Dropbox with my Debian machine to sync my local documents.
But I'm worried about putting some of my documents on the cloud after
knowing that there is a chance of breach. Because of that I avoided putting
those contents on my cloud storage. Later I figured out that we can
put an encrypted contents. I tried to use GPG and other methods to encrypt
the contents and putting them on cloud. But those are all requires lot of work to
push contents each time. GPG mainly used for transferring encrypted contents
between sender and receiver, so that is not the good solution. We required
a method to add the encrypted documents only to our cloud storage and the same
time we want to access the actual copy of the document on our machine.&lt;/p&gt;
&lt;p&gt;Then I saw options for the ecrypted file systems like &lt;strong&gt;ecryptfs&lt;/strong&gt;,
&lt;strong&gt;encfs&lt;/strong&gt; are available under Linux file systems. Which provide
good flexibility that I required, and it only required pain of one time setup.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;encfs&lt;/em&gt; is a User space filesystem, but the &lt;em&gt;ecryptfs&lt;/em&gt; is working in the kernel space,
because of that ecryptfs is little difficult to setup. But ecryptfs is faster
and more secure than the encfs. Both of them using a passphrase as the initial
key to do all the encryption and decryption, we can keep this
passphrase with other file systems or even in external storage device, This is like
normal password required to initiate the encryption or decryption.&lt;/p&gt;
&lt;p&gt;Here I'm explaining how to use the ecryptfs,&lt;/p&gt;
&lt;p&gt;First install the packages required,&lt;/p&gt;
&lt;p&gt;From root user follow these commands.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt;apt-get install ecryptfs-utils
&lt;span class="gp"&gt;#&lt;/span&gt;modprobe cryptfs
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I'm using Dropbox as my cloud storage. So inside your drobox folder just create
one folder named Encrypted.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; mkdir ~/Dropbox/Encrypted
&lt;span class="gp"&gt;$&lt;/span&gt; mkdir ~/SecureDropbox
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We are going to keep our documents under the ~/SecureDropbox folder, and the
ecryptfs will generate the corresponding encrypted files on the
~/Dropbox/Encrypted folder. So Dropbox only see this Encrypted files.&lt;/p&gt;
&lt;p&gt;Actually in terms of ecryptfs the ~/Dropbox/Encrypted act as an encrypted
file system partition(like /dev/sda5) and the ~/SecureDrobox act as the mount
point where we can see the actual content of the files, we require the proper
passphrase to mount the encrypted file system to local folder.This mounting and
creation of the encrypted file system is explained bellow.&lt;/p&gt;
&lt;p&gt;To mount the encrypted device to the mount point, use the normal mount command
with ecryptfs as its filesystem. This step ask for set of questions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Mount command requires root privilage.&lt;/span&gt;
mount -t ecryptfs /home/haridas/Dropbox/Encrypted /home/haridas/SecureDropbox
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Check this console page to see the complete list of commands required to finish
the mounting operation.&lt;/p&gt;
&lt;img alt="" src="/images/encryption-3.jpg" style="width: 100%;" /&gt;
&lt;p&gt;Now check the filesystem to see whether the encrypted filesystem got mounted
to the mount point, use df command.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; df -h
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So if there is no error, you can now check for the file encryption by directly
adding one text file in to &lt;cite&gt;/home/haridas/SecureDropbox&lt;/cite&gt;, immediately you can see
the encrypted file with the same name under &lt;cite&gt;/home/haridas/Dropbox/Encrypted&lt;/cite&gt;.
Try out this.&lt;/p&gt;
&lt;p&gt;So we are done with the keeping only the encrypted files under Dropbox folder.
So don't need to worry about the sensitive documents. But one thing is that in
order to decrypt the files from other machines, you required the passphrase and
other machines should support the ecryptfs. You can't us mobile
devices to view the encrypted content.&lt;/p&gt;
&lt;p&gt;We need to mount the ecryptefs filesystem in the boot time to avoid that step
every time. That requires passphrase, and set of other configurations, that was
done while mounting the file system initially. We can pass this automatically by
putting it in a &lt;cite&gt;.ecryptfsrc&lt;/cite&gt; file under root home directory. So at boot time
we can see system can read it.&lt;/p&gt;
&lt;p&gt;The &lt;cite&gt;/root/.ecryptfsrc&lt;/cite&gt; file should have the following lines&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;key=passphrase:passphrase_passwd_file=/home/haridas/.ecryptfs/.secret-passphrase.txt
ecryptfs_sig=b2f118ee01beb78b
ecryptfs_cipher=aes
ecryptfs_key_bytes=32
ecryptfs_passthrough=n
ecryptfs_enable_filename_crypto=n
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After creating /root/.ecryptfsrc file, add the following line to &lt;cite&gt;/etc/fstab&lt;/cite&gt;
to automount at boot time.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="sr"&gt;/home/&lt;/span&gt;haridas&lt;span class="sr"&gt;/Dropbox/&lt;/span&gt;Encrypted &lt;span class="sr"&gt;/home/&lt;/span&gt;haridas/SecureDropbox  ecryptfs
defaults &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The passphrase is the important thing that you have to keep in your machine or
with external disk. Make sure that the passphrase is available to the system
when you are trying to mount it in the booting time itself.&lt;/p&gt;
&lt;p&gt;Keep the passphrase safe !. Which determines the strength of your encryption.&lt;/p&gt;
&lt;p&gt;Enjoy.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;NOTE:&lt;/dt&gt;
&lt;dd&gt;Please check the comments by &amp;quot;Jean-Sébastien Iker&amp;quot;, He suggested a good
alternative of encrypting entire home directory using the inbuilt tool
available with the ecryptfs utils package. sdfasd&lt;/dd&gt;
&lt;/dl&gt;
</content><category term="devops"></category><category term="security"></category><category term="server"></category></entry><entry><title>Find the Absolute path in Shell Script</title><link href="https://haridas.in/find-the-absolute-path-in-shell-script.html" rel="alternate"></link><published>2011-11-19T06:01:00+05:30</published><updated>2011-11-19T06:01:00+05:30</updated><author><name>HN</name></author><id>tag:haridas.in,2011-11-19:/find-the-absolute-path-in-shell-script.html</id><summary type="html">&lt;p&gt;This is a simple shell script snippet to get the full absolute path of
that file while running it in a shell environment.&lt;/p&gt;
&lt;p&gt;What is the use of this script -- Yeah, this script is really helpful
when you are looking for a stable deployment of a multi-file project in
a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a simple shell script snippet to get the full absolute path of
that file while running it in a shell environment.&lt;/p&gt;
&lt;p&gt;What is the use of this script -- Yeah, this script is really helpful
when you are looking for a stable deployment of a multi-file project in
a Unix based systems. For these type of deployments you have to deal
with the SYSTEM_PATH and PROJECT_HOME_DIR etc, to make our project run
properly by including relative files correctly from the system path.
Commonly what we do is, we hard code the SYSTEM PATH information to a
Global variable so that would resolve every relative path
properly. So how it would be, if we don't need to hard code the
Project Bases paths, instead the project configurations detect it
automatically :). So you could get this by using this shell script
snippet.&lt;/p&gt;
&lt;p&gt;Here we can test how a shell script identify itself where it's located
or its absolute path information.Please create a shell script with
following content and run it from different locations.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#Add this content in a shell.sh,&lt;/span&gt;
&lt;span class="c1"&gt;#and then run it from different directory level, you can see the&lt;/span&gt;
&lt;span class="c1"&gt;#difference.&lt;/span&gt;

&lt;span class="nv"&gt;curr_dir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nv"&gt;dir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;dirname &lt;span class="nv"&gt;$0&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nv"&gt;FILE_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt;  &lt;span class="nv"&gt;$dir&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Path to this file : &lt;/span&gt;&lt;span class="nv"&gt;$FILE_PATH&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add this script to &lt;strong&gt;/usr/local/&lt;/strong&gt; and run it ( We know that
its current locations is &lt;strong&gt;/usr/local/&lt;/strong&gt;)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; /
&lt;span class="gp"&gt;#&lt;/span&gt;sh /usr/local/shell.sh
&lt;span class="go"&gt;Absolute PATH : /usr/local&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; /usr
&lt;span class="gp"&gt;#&lt;/span&gt; sh local/shell.sh
&lt;span class="go"&gt;Absolute PATH : /usr/local&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nb"&gt;local&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;sh shell.sh
&lt;span class="go"&gt;Absolute PATH : /usr/local&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I hope the output of the script explained every thing. So you can use
it in your projects to detect the current path automatically. Hope you
enjoyed this hack.&lt;/p&gt;
</content><category term="devops"></category><category term="server admin"></category><category term="shell"></category></entry></feed>